Q1: Multi-Layer Fully Connected Neural Networks
The notebook FullyConnectedNets.ipynb will have you implement fully connected networks of arbitrary depth. To optimize these models you will implement several popular update rules.

Q2: Batch Normalization
In notebook BatchNormalization.ipynb you will implement batch normalization, and use it to train deep fully connected networks.

Q3: Dropout
The notebook Dropout.ipynb will help you implement dropout and explore its effects on model generalization.

Q4: Convolutional Neural Networks
In the notebook ConvolutionalNetworks.ipynb you will implement several new layers that are commonly used in convolutional networks.

Q5: PyTorch on CIFAR-10
For this part, you will be working with PyTorch, a popular and powerful deep learning framework.

Open up PyTorch.ipynb. There, you will learn how the framework works, culminating in training a convolutional network of your own design on CIFAR-10 to get the best performance you can.